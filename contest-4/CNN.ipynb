{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_DIR = 'train/train/'\n",
    "TEST_DIR = 'test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apricot': 0,\n",
       " 'Avocado': 1,\n",
       " 'Limes': 2,\n",
       " 'Cherry': 3,\n",
       " 'Plum': 4,\n",
       " 'Potato Red': 5,\n",
       " 'Peach': 6,\n",
       " 'Blueberry': 7,\n",
       " 'Corn': 8,\n",
       " 'Mango': 9,\n",
       " 'Apple Braeburn': 10,\n",
       " 'Banana': 11,\n",
       " 'Kiwi': 12,\n",
       " 'Strawberry': 13,\n",
       " 'Pear': 14,\n",
       " 'Cucumber Ripe': 15,\n",
       " 'Pineapple': 16,\n",
       " 'Tomato': 17,\n",
       " 'Pomegranate': 18,\n",
       " 'Orange': 19,\n",
       " 'Watermelon': 20,\n",
       " 'Passion Fruit': 21,\n",
       " 'Pepper Red': 22,\n",
       " 'Cantaloupe': 23,\n",
       " 'Onion White': 24,\n",
       " 'Clementine': 25,\n",
       " 'Papaya': 26,\n",
       " 'Raspberry': 27,\n",
       " 'Lemon': 28,\n",
       " 'Grape Blue': 29,\n",
       " 'Apple Granny Smith': 30,\n",
       " 'Cactus fruit': 31,\n",
       " 'Pepper Green': 32}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {}\n",
    "filenames = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for dir in dirs:\n",
    "        dict[dir] = len(dict)\n",
    "    for file in files:\n",
    "        filenames.append(file)\n",
    "\n",
    "IMGS = len(filenames)\n",
    "CLASSES = len(dict)        \n",
    "\n",
    "X_train = np.zeros((IMGS, 100, 100, 3))\n",
    "y_train = np.zeros((IMGS, CLASSES))\n",
    "\n",
    "for i in range(IMGS):\n",
    "    food = filenames[i].split('_')[0]\n",
    "    X_train[i] = cv2.imread(TRAIN_DIR + food + '/' + filenames[i])\n",
    "    y_train[i][dict[food]] = 1\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, samplewise_center=False,\n",
    "    featurewise_std_normalization=True, samplewise_std_normalization=False,\n",
    "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=30, width_shift_range=0.05,\n",
    "    height_shift_range=0.05, brightness_range=None, shear_range=5.0, zoom_range=0.0,\n",
    "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=True,\n",
    "    vertical_flip=True, rescale=None, preprocessing_function=None,\n",
    "    data_format='channels_last', validation_split=0.1, dtype=None\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 526.6875 steps\n",
      "Epoch 1/5\n",
      "527/526 [==============================] - 46s 87ms/step - loss: 2.7310\n",
      "Epoch 2/5\n",
      "  2/526 [..............................] - ETA: 1:06 - loss: 1.8930"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "EPOCHS = 5\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Xception(\n",
    "    include_top=False, weights='imagenet', input_tensor=None, input_shape=(100, 100, 3),\n",
    "    pooling='avg'))\n",
    "model.add(Dense(CLASSES, activation = 'softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer=opt, loss=cce)\n",
    "\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32, shuffle = True),\n",
    "          steps_per_epoch = IMGS / 32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python37664bittfgpuconda260f91e199e24d2480a726ccf93212d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
